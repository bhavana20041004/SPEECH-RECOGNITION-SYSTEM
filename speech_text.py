# -*- coding: utf-8 -*-
"""speech-text.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1slAR5tFJIEacy2j_-05YofXAfC189fWV
"""

!pip install --upgrade transformers

import transformers
print(transformers.__version__)

import librosa
import torch
import IPython.display as display
from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer
import numpy as np
tokenizer = Wav2Vec2Tokenizer.from_pretrained("facebook/wav2vec2-base-960h")
model = Wav2Vec2ForCTC.from_pretrained("facebook/wav2vec2-base-960h")

from google.colab import files

uploaded = files.upload()

import os

os.rename("WhatsApp Audio 2025-06-22 at 15.53.00_0b91cce5.dat.unknown", "myspeech.m4a")

Audio("myspeech.m4a", autoplay=True)

import librosa
import soundfile as sf


audio, sr = librosa.load("myspeech.m4a", sr=16000)


sf.write("myspeech.wav", audio, sr)

import torch
import torchaudio
from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor


processor = Wav2Vec2Processor.from_pretrained("facebook/wav2vec2-base-960h")
model = Wav2Vec2ForCTC.from_pretrained("facebook/wav2vec2-base-960h")


waveform, sample_rate = torchaudio.load("myspeech.wav")


if sample_rate != 16000:
    resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)
    waveform = resampler(waveform)


input_values = processor(waveform.squeeze().numpy(), return_tensors="pt", sampling_rate=16000).input_values


with torch.no_grad():
    logits = model(input_values).logits


predicted_ids = torch.argmax(logits, dim=-1)
transcription = processor.decode(predicted_ids[0])


print("üó£Ô∏è Transcribed Text:\n", transcription)

